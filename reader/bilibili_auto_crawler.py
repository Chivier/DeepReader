"""
Bilibili è‡ªåŠ¨è§†é¢‘æœç´¢å’Œä¸‹è½½æ¨¡å—
è‡ªåŠ¨æœç´¢å’Œè¿™æœ¬ä¹¦ç›¸å…³çš„ï¼Œè¶…è¿‡ 5 åˆ†é’Ÿçš„ä¸­é•¿è§†é¢‘
"""

import requests
import json
import time
import os
import re
from datetime import datetime
import yt_dlp
from typing import List, Dict, Optional

class BilibiliAutoCrawler:
    """Bilibili è‡ªåŠ¨çˆ¬è™«ç±»"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Referer': 'https://www.bilibili.com/'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        
    def search_videos(self, book_name: str, min_duration: int = 300) -> List[Dict]:
        """
        æœç´¢ä¸ä¹¦ç±ç›¸å…³çš„è§†é¢‘
        
        Args:
            book_name: ä¹¦ç±åç§°
            min_duration: æœ€å°æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤5åˆ†é’Ÿ
            
        Returns:
            è§†é¢‘ä¿¡æ¯åˆ—è¡¨
        """
        print(f"æ­£åœ¨æœç´¢ã€Š{book_name}ã€‹ç›¸å…³è§†é¢‘...")
        
        # æ„å»ºæœç´¢å…³é”®è¯
        search_keywords = [
            f"{book_name} ä¹¦è¯„",
            f"{book_name} è§£è¯»",
            f"{book_name} åˆ†æ",
            f"{book_name} è¯»åæ„Ÿ",
            f"{book_name} æ¨è"
        ]
        
        all_videos = []
        
        for keyword in search_keywords:
            try:
                videos = self._search_single_keyword(keyword, min_duration)
                all_videos.extend(videos)
                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            except Exception as e:
                print(f"æœç´¢å…³é”®è¯ '{keyword}' æ—¶å‡ºé”™: {e}")
                continue
        
        # å»é‡å’Œæ’åº
        unique_videos = self._deduplicate_videos(all_videos)
        sorted_videos = sorted(unique_videos, key=lambda x: x.get('play_count', 0), reverse=True)
        
        print(f"æ‰¾åˆ° {len(sorted_videos)} ä¸ªç›¸å…³è§†é¢‘")
        return sorted_videos[:10]  # è¿”å›å‰10ä¸ªæœ€çƒ­é—¨çš„è§†é¢‘
    
    def _search_single_keyword(self, keyword: str, min_duration: int) -> List[Dict]:
        """æœç´¢å•ä¸ªå…³é”®è¯"""
        search_url = "https://api.bilibili.com/x/web-interface/search/type"
        
        params = {
            'search_type': 'video',
            'keyword': keyword,
            'order': 'totalrank',  # æŒ‰ç»¼åˆæ’åº
            'duration': 3,  # 10-30åˆ†é’Ÿ
            'page': 1,
            'page_size': 20
        }
        
        try:
            response = self.session.get(search_url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            if data.get('code') != 0:
                print(f"APIè¿”å›é”™è¯¯: {data.get('message', 'Unknown error')}")
                return []
            
            videos = []
            for item in data.get('data', {}).get('result', []):
                video_info = self._parse_video_info(item)
                if video_info and video_info.get('duration', 0) >= min_duration:
                    videos.append(video_info)
            
            return videos
            
        except Exception as e:
            print(f"æœç´¢è¯·æ±‚å¤±è´¥: {e}")
            return []
    
    def _parse_video_info(self, item: Dict) -> Optional[Dict]:
        """è§£æè§†é¢‘ä¿¡æ¯"""
        try:
            # è§£ææ—¶é•¿
            duration_str = item.get('duration', '')
            duration = self._parse_duration(duration_str)
            
            # è§£ææ’­æ”¾é‡
            play_count = self._parse_play_count(item.get('play', ''))
            
            video_info = {
                'bvid': item.get('bvid', ''),
                'title': self._clean_title(item.get('title', '')),
                'author': item.get('author', ''),
                'duration': duration,
                'play_count': play_count,
                'description': item.get('description', ''),
                'url': f"https://www.bilibili.com/video/{item.get('bvid', '')}",
                'pic': item.get('pic', ''),
                'pubdate': item.get('pubdate', 0)
            }
            
            return video_info
            
        except Exception as e:
            print(f"è§£æè§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def _parse_duration(self, duration_str: str) -> int:
        """è§£ææ—¶é•¿å­—ç¬¦ä¸²ä¸ºç§’æ•°"""
        try:
            if not duration_str:
                return 0
            
            parts = duration_str.split(':')
            if len(parts) == 2:
                minutes, seconds = map(int, parts)
                return minutes * 60 + seconds
            elif len(parts) == 3:
                hours, minutes, seconds = map(int, parts)
                return hours * 3600 + minutes * 60 + seconds
            else:
                return 0
        except:
            return 0
    
    def _parse_play_count(self, play_str: str) -> int:
        """è§£ææ’­æ”¾é‡å­—ç¬¦ä¸²ä¸ºæ•°å­—"""
        try:
            if not play_str:
                return 0
            
            # ç§»é™¤HTMLæ ‡ç­¾
            play_str = re.sub(r'<[^>]+>', '', play_str)
            
            # å¤„ç†ä¸‡ã€åƒç­‰å•ä½
            if 'ä¸‡' in play_str:
                number = float(re.search(r'([\d.]+)', play_str).group(1))
                return int(number * 10000)
            elif 'åƒ' in play_str:
                number = float(re.search(r'([\d.]+)', play_str).group(1))
                return int(number * 1000)
            else:
                number = re.search(r'(\d+)', play_str)
                return int(number.group(1)) if number else 0
                
        except:
            return 0
    
    def _clean_title(self, title: str) -> str:
        """æ¸…ç†æ ‡é¢˜ä¸­çš„HTMLæ ‡ç­¾"""
        return re.sub(r'<[^>]+>', '', title)
    
    def _deduplicate_videos(self, videos: List[Dict]) -> List[Dict]:
        """å»é™¤é‡å¤è§†é¢‘"""
        seen_bvids = set()
        unique_videos = []
        
        for video in videos:
            bvid = video.get('bvid', '')
            if bvid and bvid not in seen_bvids:
                seen_bvids.add(bvid)
                unique_videos.append(video)
        
        return unique_videos
    
    def download_videos(self, videos: List[Dict], book_name: str, max_videos: int = 3) -> List[str]:
        """
        ä¸‹è½½è§†é¢‘å’Œå­—å¹•
        
        Args:
            videos: è§†é¢‘ä¿¡æ¯åˆ—è¡¨
            book_name: ä¹¦ç±åç§°
            max_videos: æœ€å¤§ä¸‹è½½æ•°é‡
            
        Returns:
            ä¸‹è½½æˆåŠŸçš„è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        if not videos:
            print("æ²¡æœ‰å¯ä¸‹è½½çš„è§†é¢‘")
            return []
        
        # åˆ›å»ºä¸‹è½½ç›®å½•
        download_dir = f"{book_name}/video"
        os.makedirs(download_dir, exist_ok=True)
        
        downloaded_files = []
        
        # é…ç½® yt-dlp
        ydl_opts = {
            'outtmpl': f'{download_dir}/%(title)s.%(ext)s',
            'format': 'best[height<=720]',  # é™åˆ¶åˆ†è¾¨ç‡ä»¥èŠ‚çœç©ºé—´
            'writesubtitles': True,  # ä¸‹è½½å­—å¹•
            'writeautomaticsub': True,  # ä¸‹è½½è‡ªåŠ¨ç”Ÿæˆçš„å­—å¹•
            'subtitleslangs': ['zh-CN', 'zh-Hans', 'zh'],  # ä¸­æ–‡å­—å¹•
            'ignoreerrors': True,  # å¿½ç•¥é”™è¯¯ç»§ç»­ä¸‹è½½
        }
        
        print(f"å¼€å§‹ä¸‹è½½å‰ {min(max_videos, len(videos))} ä¸ªè§†é¢‘...")
        
        for i, video in enumerate(videos[:max_videos]):
            try:
                print(f"æ­£åœ¨ä¸‹è½½ç¬¬ {i+1} ä¸ªè§†é¢‘: {video['title']}")
                
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    ydl.download([video['url']])
                
                # è®°å½•ä¸‹è½½ä¿¡æ¯
                info_file = f"{download_dir}/video_{i+1}_info.json"
                with open(info_file, 'w', encoding='utf-8') as f:
                    json.dump(video, f, ensure_ascii=False, indent=2)
                
                downloaded_files.append(info_file)
                print(f"âœ… è§†é¢‘ä¸‹è½½å®Œæˆ: {video['title']}")
                
                time.sleep(2)  # ä¸‹è½½é—´éš”
                
            except Exception as e:
                print(f"âŒ ä¸‹è½½è§†é¢‘å¤±è´¥: {video['title']}, é”™è¯¯: {e}")
                continue
        
        print(f"ä¸‹è½½å®Œæˆï¼Œå…±æˆåŠŸä¸‹è½½ {len(downloaded_files)} ä¸ªè§†é¢‘")
        return downloaded_files
    
    def extract_subtitles_text(self, book_name: str) -> str:
        """
        æå–æ‰€æœ‰è§†é¢‘çš„å­—å¹•æ–‡æœ¬
        
        Args:
            book_name: ä¹¦ç±åç§°
            
        Returns:
            åˆå¹¶åçš„å­—å¹•æ–‡æœ¬
        """
        video_dir = f"{book_name}/video"
        if not os.path.exists(video_dir):
            return ""
        
        all_text = []
        
        # æŸ¥æ‰¾æ‰€æœ‰å­—å¹•æ–‡ä»¶
        subtitle_files = []
        for file in os.listdir(video_dir):
            if file.endswith(('.vtt', '.srt', '.ass')):
                subtitle_files.append(os.path.join(video_dir, file))
        
        print(f"æ‰¾åˆ° {len(subtitle_files)} ä¸ªå­—å¹•æ–‡ä»¶")
        
        for subtitle_file in subtitle_files:
            try:
                text = self._extract_text_from_subtitle(subtitle_file)
                if text:
                    all_text.append(f"# è§†é¢‘å­—å¹•: {os.path.basename(subtitle_file)}\n\n{text}\n\n")
            except Exception as e:
                print(f"æå–å­—å¹•å¤±è´¥: {subtitle_file}, é”™è¯¯: {e}")
        
        # ä¿å­˜åˆå¹¶åçš„æ–‡æœ¬
        if all_text:
            output_file = f"{video_dir}/all_subtitles.txt"
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(all_text))
            print(f"å­—å¹•æ–‡æœ¬å·²ä¿å­˜åˆ°: {output_file}")
            return '\n'.join(all_text)
        
        return ""
    
    def _extract_text_from_subtitle(self, subtitle_file: str) -> str:
        """ä»å­—å¹•æ–‡ä»¶æå–çº¯æ–‡æœ¬"""
        with open(subtitle_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # å¤„ç†ä¸åŒçš„å­—å¹•æ ¼å¼
        if subtitle_file.endswith('.vtt'):
            return self._extract_from_vtt(content)
        elif subtitle_file.endswith('.srt'):
            return self._extract_from_srt(content)
        else:
            # ç®€å•çš„æ–‡æœ¬æå–
            lines = content.split('\n')
            text_lines = []
            for line in lines:
                line = line.strip()
                if line and not line.startswith(('WEBVTT', 'NOTE', '{')):
                    # ç§»é™¤æ—¶é—´æˆ³
                    if '-->' not in line and not line.isdigit():
                        text_lines.append(line)
            return '\n'.join(text_lines)
    
    def _extract_from_vtt(self, content: str) -> str:
        """ä»VTTæ ¼å¼æå–æ–‡æœ¬"""
        lines = content.split('\n')
        text_lines = []
        
        for line in lines:
            line = line.strip()
            if line and not line.startswith('WEBVTT') and '-->' not in line and not line.startswith('NOTE'):
                # ç§»é™¤HTMLæ ‡ç­¾
                line = re.sub(r'<[^>]+>', '', line)
                if line:
                    text_lines.append(line)
        
        return '\n'.join(text_lines)
    
    def _extract_from_srt(self, content: str) -> str:
        """ä»SRTæ ¼å¼æå–æ–‡æœ¬"""
        lines = content.split('\n')
        text_lines = []
        
        for line in lines:
            line = line.strip()
            if line and not line.isdigit() and '-->' not in line:
                text_lines.append(line)
        
        return '\n'.join(text_lines)
    
    def create_video_links_file(self, videos: List[Dict], book_name: str) -> str:
        """
        åˆ›å»ºè§†é¢‘é“¾æ¥æ–‡ä»¶ä¾›ä¼ ç»Ÿçˆ¬è™«ä½¿ç”¨
        
        Args:
            videos: è§†é¢‘ä¿¡æ¯åˆ—è¡¨
            book_name: ä¹¦ç±åç§°
            
        Returns:
            é“¾æ¥æ–‡ä»¶è·¯å¾„
        """
        links_file = f"{book_name}_video_links.txt"
        
        with open(links_file, 'w', encoding='utf-8') as f:
            f.write(f"# ã€Š{book_name}ã€‹ç›¸å…³è§†é¢‘é“¾æ¥\n")
            f.write(f"# ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            for i, video in enumerate(videos, 1):
                f.write(f"# {i}. {video['title']}\n")
                f.write(f"# ä½œè€…: {video['author']}\n")
                f.write(f"# æ—¶é•¿: {video['duration']}ç§’\n")
                f.write(f"# æ’­æ”¾é‡: {video['play_count']}\n")
                f.write(f"{video['url']}\n\n")
        
        print(f"è§†é¢‘é“¾æ¥æ–‡ä»¶å·²åˆ›å»º: {links_file}")
        return links_file

def auto_process_book_videos(book_name: str, download_videos: bool = True, max_videos: int = 3) -> Dict:
    """
    è‡ªåŠ¨å¤„ç†ä¹¦ç±ç›¸å…³è§†é¢‘çš„å®Œæ•´æµç¨‹
    
    Args:
        book_name: ä¹¦ç±åç§°
        download_videos: æ˜¯å¦ä¸‹è½½è§†é¢‘
        max_videos: æœ€å¤§å¤„ç†è§†é¢‘æ•°é‡
        
    Returns:
        å¤„ç†ç»“æœä¿¡æ¯
    """
    crawler = BilibiliAutoCrawler()
    
    try:
        # 1. æœç´¢è§†é¢‘
        print("ğŸ” å¼€å§‹æœç´¢ç›¸å…³è§†é¢‘...")
        videos = crawler.search_videos(book_name)
        
        if not videos:
            return {
                'success': False,
                'message': 'æœªæ‰¾åˆ°ç›¸å…³è§†é¢‘',
                'videos_found': 0
            }
        
        # 2. åˆ›å»ºé“¾æ¥æ–‡ä»¶
        print("ğŸ“ åˆ›å»ºè§†é¢‘é“¾æ¥æ–‡ä»¶...")
        links_file = crawler.create_video_links_file(videos, book_name)
        
        result = {
            'success': True,
            'videos_found': len(videos),
            'links_file': links_file,
            'videos': videos
        }
        
        # 3. ä¸‹è½½è§†é¢‘ï¼ˆå¯é€‰ï¼‰
        if download_videos:
            print("â¬‡ï¸ å¼€å§‹ä¸‹è½½è§†é¢‘...")
            downloaded_files = crawler.download_videos(videos, book_name, max_videos)
            result['downloaded_files'] = downloaded_files
            result['downloaded_count'] = len(downloaded_files)
            
            # 4. æå–å­—å¹•
            print("ğŸ“„ æå–å­—å¹•æ–‡æœ¬...")
            subtitle_text = crawler.extract_subtitles_text(book_name)
            result['subtitle_text'] = subtitle_text
            result['has_subtitles'] = bool(subtitle_text)
        
        print(f"âœ… è§†é¢‘å¤„ç†å®Œæˆï¼æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘")
        return result
        
    except Exception as e:
        print(f"âŒ è§†é¢‘å¤„ç†å¤±è´¥: {e}")
        return {
            'success': False,
            'message': str(e),
            'videos_found': 0
        }

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    book_name = "ä¸‰ä½“"
    result = auto_process_book_videos(book_name, download_videos=False)
    print(json.dumps(result, ensure_ascii=False, indent=2))